{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "#c-rnn-gan\n",
    "#char-rnn 을 gan형식으로 제작할 것. dur fre vel\n",
    "\n",
    "lstm_dim = 350\n",
    "song_feature = 4\n",
    "start_num = 0\n",
    "batch_size = 50\n",
    "max_song_size = 200\n",
    "global EPOCH\n",
    "EPOCH = 200\n",
    "isAdam = True\n",
    "AdamLearningrate = {'G': 0.05, 'D': 0.05, 'P': 1e-8}\n",
    "GDLearningrate = {'G': 0.1, 'D': 0.1, 'P': 1e-7}\n",
    "print_batch = 1\n",
    "save_batch = 50\n",
    "DEBUG = True\n",
    "reg_scale = 0.5\n",
    "\n",
    "\n",
    "#final multiply in G\n",
    "song_num = {'train': 0, 'validation': 0, 'test': 0}\n",
    "song_var = {'train': 0, 'validation': 0, 'test': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_batch():\n",
    "    song_num['train'] = len(os.listdir('./train'))\n",
    "    song_num['validation'] = len(os.listdir('./validation'))\n",
    "    song_num['test'] = len(os.listdir('./test'))\n",
    "\n",
    "\n",
    "def get_batch(what='train'):\n",
    "    out_batch = []\n",
    "    start_ptn = song_var[what]\n",
    "    end_ptn = start_ptn + batch_size\n",
    "    if end_ptn>song_num[what]:\n",
    "        for i in range(start_ptn, song_num[what]):\n",
    "            tmp_in = np.load('./'+what+'/'+str(i)+'.npy')\n",
    "            out_batch.append(tmp_in)\n",
    "        for i in range(0, end_ptn%song_num[what]):\n",
    "            tmp_in = np.load('./'+what+'/'+str(i)+'.npy')\n",
    "            out_batch.append(tmp_in)\n",
    "    else:\n",
    "        for i in range(start_ptn, end_ptn):\n",
    "            tmp_in = np.load('./'+what+'/'+str(i)+'.npy')\n",
    "            out_batch.append(tmp_in)\n",
    "\n",
    "    song_var[what] = end_ptn%song_num[what]\n",
    "    return out_batch\n",
    "\n",
    "def get_batch_matrix(what = 'train'):\n",
    "    song_data = np.zeros([batch_size, max_song_size, song_feature], dtype=np.uint32)\n",
    "    song_getsoo = []\n",
    "    read_batch = get_batch(what)\n",
    "    for i, newbat in enumerate(read_batch):\n",
    "        tmp_max = max_song_size\n",
    "        if max_song_size > newbat.shape[0]:\n",
    "            tmp_max = newbat.shape[0]\n",
    "        song_data[i, :tmp_max, :] = newbat[:tmp_max, :]\n",
    "        song_getsoo.append(tmp_max)\n",
    "    return song_data, song_getsoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(inp, out_dim, scope_name, reuse=False):\n",
    "    with tf.variable_scope(scope_name, reuse=reuse):\n",
    "        from_dim = int(inp.shape[1])\n",
    "        lin_w = tf.get_variable('lin_w', [from_dim,out_dim], dtype = tf.float32, initializer = tf.truncated_normal_initializer)\n",
    "        lin_b = tf.get_variable('lin_b', [out_dim], dtype = tf.float32, initializer = tf.truncated_normal_initializer)\n",
    "    return tf.matmul(inp, lin_w)+lin_b\n",
    "\n",
    "\n",
    "def lstmcell(outdim_size = lstm_dim):\n",
    "    return tf.contrib.rnn.BasicLSTMCell(outdim_size)\n",
    "\n",
    "\n",
    "def dropout_lstm_cell(outdim_size = lstm_dim, keep_prob = 0.6):\n",
    "    cell = lstmcell(outdim_size)\n",
    "    cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob = keep_prob)\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_list_fw = [lstmcell(lstm_dim) for _ in range(3)]\n",
    "cell_list_bw = [lstmcell(lstm_dim) for _ in range(3)]\n",
    "\n",
    "\n",
    "def discriminator(x_input, x_size):\n",
    "    # Batch Normal\n",
    "    #x_input = tf.contrib.layers.batch_norm(x_input)\n",
    "    lstm_fw = tf.contrib.rnn.MultiRNNCell(cell_list_fw)\n",
    "    lstm_bw = tf.contrib.rnn.MultiRNNCell(cell_list_bw)\n",
    "    output, _ = tf.nn.bidirectional_dynamic_rnn(lstm_fw,lstm_bw, x_input, x_size, dtype= tf.float32)\n",
    "    return output[0], output[1]\n",
    "\n",
    "\n",
    "def generator(z_prior, z_size):\n",
    "    lstm = tf.contrib.rnn.MultiRNNCell([lstmcell() for _ in range(3)])\n",
    "    output, _ = tf.nn.dynamic_rnn(lstm, z_prior, dtype= tf.float32, sequence_length = z_size)\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_dis_res(two_added_mean, scope_name, reuse=False):\n",
    "    with tf.variable_scope(scope_name, reuse=reuse):\n",
    "        dis_res = tf.reshape(two_added_mean, [-1, lstm_dim])\n",
    "        dis_res = linear(dis_res, 1, scope_name+'_lin', reuse=reuse)\n",
    "        dis_res = tf.sigmoid(dis_res)\n",
    "        dis_res = tf.reshape(dis_res, [batch_size, max_song_size])\n",
    "        dis_res = tf.reduce_mean(dis_res, axis=1)\n",
    "    return dis_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global EPOCH\n",
    "init_batch()\n",
    "save_cnt = tf.Variable(0, dtype=tf.int32, name='global_step')\n",
    "z_in = tf.random_uniform([batch_size, max_song_size, lstm_dim],minval = 0.0, maxval=1.0)\n",
    "z_size = tf.constant(max_song_size, dtype= tf.int32, shape=[batch_size])\n",
    "x_in = tf.placeholder(tf.float32, shape = [batch_size, max_song_size, song_feature])\n",
    "x_size = tf.placeholder(tf.int32, shape = [batch_size])\n",
    "with tf.variable_scope(\"Generator\") as scope:\n",
    "    scope.set_regularizer(tf.contrib.layers.l2_regularizer(scale=reg_scale))\n",
    "    gen = generator(z_in, z_size)\n",
    "    gen = tf.reshape(gen,[-1, lstm_dim])\n",
    "    gen = linear(gen, song_feature, 'gen_linear')\n",
    "    gen_res = tf.reshape(gen, [-1, max_song_size, song_feature])\n",
    "    generator_variables = [v for v in tf.global_variables()\n",
    "                           if v.name.startswith(scope.name)]\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"discriminator\") as scope2:\n",
    "    scope2.set_regularizer(tf.contrib.layers.l2_regularizer(scale=reg_scale))\n",
    "    gen_converted = linear(gen, lstm_dim, 'dis_lin')\n",
    "    print(gen_converted.shape)\n",
    "    gen_converted = tf.reshape(gen_converted,[-1, max_song_size, lstm_dim])\n",
    "    dis_gen_fw, dis_gen_bw = discriminator(gen_converted, z_size)\n",
    "    dis_calc_in_loss_gen = (dis_gen_fw+dis_gen_bw)/2\n",
    "    dis_res_gen = get_dis_res(dis_calc_in_loss_gen, 'dis_res')\n",
    "    scope2.reuse_variables()\n",
    "    x_in_cv = tf.reshape(x_in, [-1, song_feature])\n",
    "    x_in_cv = linear(x_in_cv, lstm_dim, 'dis_lin', reuse=True)\n",
    "    print(x_in_cv)\n",
    "    x_in_cv = tf.reshape(x_in_cv, [-1,max_song_size, lstm_dim])\n",
    "    dis_real_fw, dis_real_bw = discriminator(x_in_cv, x_size)\n",
    "    dis_calc_in_loss_real = (dis_real_fw+dis_real_bw)/2\n",
    "    dis_res_real = get_dis_res(dis_calc_in_loss_real, 'dis_res', reuse=True)\n",
    "    #D Loss를 위한 식\n",
    "    dis_variables = [v for v in tf.global_variables()\n",
    "                     if v.name.startswith(scope2.name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_real = tf.round(dis_res_real)\n",
    "predict_gen = tf.round(dis_res_gen)\n",
    "accuracy_res = (tf.reduce_mean(predict_real) + tf.reduce_mean(1-predict_gen))/2\n",
    "print('genvars: ', generator_variables)\n",
    "print('disvars: ', dis_variables)\n",
    "# Generator Feature Matching Loss\n",
    "\n",
    "g_fm_loss = tf.reduce_sum(tf.squared_difference(dis_calc_in_loss_real, dis_calc_in_loss_gen))\n",
    "d_loss = tf.reduce_mean(-tf.log(tf.clip_by_value(dis_res_real, 1e-20, 1))-tf.log(tf.clip_by_value(1.0 - dis_res_gen, 1e-20, 1)))\n",
    "train_AdamG = tf.train.AdamOptimizer(AdamLearningrate['G']).minimize(g_fm_loss, var_list = generator_variables)\n",
    "train_AdamD = tf.train.AdamOptimizer(AdamLearningrate['D']).minimize(d_loss, var_list = dis_variables)\n",
    "\n",
    "trainG = tf.train.GradientDescentOptimizer(GDLearningrate['G']).minimize(g_fm_loss, var_list = generator_variables)\n",
    "trainD = tf.train.GradientDescentOptimizer(GDLearningrate['D']).minimize(d_loss, var_list = dis_variables)\n",
    "\n",
    "pretrain_loss = tf.reduce_sum(tf.squared_difference(gen_res, x_in))\n",
    "\n",
    "train_pre_G = tf.train.GradientDescentOptimizer(GDLearningrate['P']).minimize(pretrain_loss)\n",
    "train_pre_A = tf.train.AdamOptimizer(AdamLearningrate['P']).minimize(pretrain_loss)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saved_loc = tf.train.latest_checkpoint('./saved_model/')\n",
    "    print(saved_loc)\n",
    "    cnt_step = 0\n",
    "    EPOCH_start = 0\n",
    "\n",
    "    if saved_loc is None:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('No Saved Session')\n",
    "    else:\n",
    "        saver.restore(sess, saved_loc)\n",
    "        cnt_step = save_cnt.eval(sess)\n",
    "        EPOCH_start = (batch_size * cnt_step) // song_num['train']\n",
    "        song_var['train'] = (batch_size * cnt_step) % song_num['train']\n",
    "        print('Saved Session Found step: ', cnt_step)\n",
    "    EPOCH_start = 6\n",
    "    for epoch in range(EPOCH_start, 6):\n",
    "        while True:\n",
    "            song_data, song_getsoo = get_batch_matrix()\n",
    "            #Pretraining\n",
    "            pretrain_dict = {x_in: song_data, x_size: song_getsoo}\n",
    "            if isAdam:\n",
    "                _, p_loss =  sess.run([train_pre_A, pretrain_loss], feed_dict = pretrain_dict)\n",
    "            else:\n",
    "                _, p_loss = sess.run([train_pre_G, pretrain_loss], feed_dict = pretrain_dict)\n",
    "            print('P: ', p_loss)\n",
    "            if song_var['train'] + batch_size > song_num['train']:\n",
    "                break\n",
    "\n",
    "\n",
    "    print('Pre train completed')\n",
    "\n",
    "    for epoch in range(EPOCH_start, EPOCH):\n",
    "        while True:\n",
    "            song_data, song_getsoo = get_batch_matrix()\n",
    "            train_dict = {x_in: song_data, x_size: song_getsoo}\n",
    "            # Freezing을 위한 Accuracy 구하기\n",
    "            accuracy = sess.run(accuracy_res, feed_dict=train_dict)\n",
    "            print('accuracy : ', accuracy)\n",
    "            if isAdam:\n",
    "                train_tens_G = train_AdamG\n",
    "                train_tens_D = train_AdamD\n",
    "            else:\n",
    "                train_tens_G = trainG\n",
    "                train_tens_D = trainD\n",
    "            if accuracy>=0.7:\n",
    "                train_g_loss, train_d_loss, _, generated, dis_res_see_gen, dis_res_see_real = sess.run(\n",
    "                    [g_fm_loss, d_loss, train_tens_G, gen_res, dis_res_gen, dis_res_real],\n",
    "                    feed_dict=train_dict)\n",
    "            else:\n",
    "                train_g_loss, train_d_loss, _, _, generated, dis_res_see_gen, dis_res_see_real = sess.run([g_fm_loss, d_loss, train_tens_D, train_tens_G, gen_res, dis_res_gen, dis_res_real],\n",
    "                                                                                                          feed_dict=train_dict)\n",
    "            generated = generated.astype(int)\n",
    "            print(generated.shape)\n",
    "            np.savetxt('generated_song.txt', generated[0])\n",
    "            print('Generated', generated[0][-1])\n",
    "            if cnt_step % print_batch == 0:\n",
    "                print('epoch: ', epoch, ' cnt_step_num: ', cnt_step, ' G loss: ', train_g_loss,' D loss: ', train_d_loss)\n",
    "            print(song_var['train'], ' ', song_num['train'])\n",
    "            cnt_step += 1\n",
    "            print('gen_weight', sess.run(generator_variables[-2]))\n",
    "            sess.run(tf.assign(save_cnt, cnt_step))\n",
    "            if cnt_step % save_batch == 1:\n",
    "                saver.save(sess, './saved_model/model.ckpt', global_step = cnt_step)\n",
    "            if song_var['train'] + batch_size > song_num['train']:\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
